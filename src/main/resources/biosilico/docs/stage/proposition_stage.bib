% This file was created with JabRef 2.4.2.
% Encoding: Cp1252

@INPROCEEDINGS{GeShSa04,
  author = {Germ{\'a}n-Soto, Ernesto and Sheremetov, Leonid B. and S{\'a}nchez-S{\'a}nchez,
	Christian},
  title = {Interaction Modeling with Artificial Life Agents},
  booktitle = {Intelligent Virtual Environments and Virtual Agents (IVEVA)},
  year = {2004},
  editor = {ITESM Campus Ciudad de Mexico -- Mexico City -- D.F -- Mexico --
	April 27th 2004},
  volume = {97},
  month = {April},
  abstract = {In this work, an interaction model between artificial life agents
	(creatures) is proposed, which allows studying emergent social behavior
	of agents. This model describes the environment of artificial life
	and autonomous creatures in terms of goal-states, rules of behavior
	based on agents' goals and actions, initial knowledge and the use
	of communication instructions. For the case of study, the technology
	and environment of Creatures Labs are used to implement artificial
	life agents based on the proposed model. },
  citeseerurl = {http://citeseer.ist.psu.edu/695112.html},
  date-added = {2009-04-26 14:00:50 +0200},
  date-modified = {2009-04-26 14:20:21 +0200},
  doi = {10.1.1.58.2738},
  keywords = {artificial life},
  url = {http://ftp.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-97/}
}

@ARTICLE{GraCli97,
  author = {Grand, Stephen and Cliff, Dave},
  title = {Creatures: Entertainment Software Agents with Artificial Life},
  journal = {Autonomous Agents and Multi-Agent Systems},
  year = {1997},
  volume = {100},
  pages = {1--20},
  abstract = {We present a technical description of Creatures, a commercial home-entertainment
	software package. Creatures provides a simulatedenvironment in which
	exist a number of synthetic agents that a user can interact with
	in real-time. The agents (known as "creatures") are intended as sophisticated
	"virtual pets". The internal architecture of the creatures is strongly
	inspired by animal biology. Each creature has a neural network responsible
	for sensory-motorcoordinationand behavior selection, and an "artificial
	biochemistry" that models a simple energy metabolism along with a
	"hormonal" system that interacts with the neural network to model
	diffuse modulation of neuronal activity and staged ontogenetic development.
	A biologically inspired learning mechanism allows the neural network
	to adapt during the lifetime of a creature. Learning includes the
	ability to acquire a simple verb--object language.
	
	
	Additionnally, both of the network architecture and details of the
	biochemistry for a creature are specified in a variable--length ``genetic''
	encoding, allowing for evolutionary adaptation through sexual reproduction.
	Creatures, available on Windows95 platforms since late 1996, offers
	users an opportunity to engage with Artificial Life Technologies.
	In addition to describing technical details, this papers concludes
	with a discussion of the scientific implications of the system.},
  citeseerurl = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.18.9182},
  date-added = {2009-04-26 14:07:09 +0200},
  date-modified = {2009-04-26 14:10:07 +0200},
  doi = {10.1.1.18.9182},
  keywords = {Artificial Life,Adaptative Behavior,Evolutionnary Computation,Entertainment
	Softwarecreatures,artificial life,hormonal system,neural network,artificial
	biochemistry,agent}
}

@INPROCEEDINGS{GrClMa97,
  author = {Grand, Stephen and Cliff, Dave and Malhotra, Anil},
  title = {Creatures: Artificial Life Autonomous Software Agents for Home Entertainment},
  booktitle = {Agents '97 Conference Proceedings},
  year = {1997},
  series = {Proceedings of the first international conference on Autonomous agents},
  pages = {22-29},
  address = {Marina del Rey, California, United States},
  organization = {Millenium Interactive},
  publisher = {International Conference on Autonomous Agents},
  abstract = {This paper gives a technical description of Creatures, a commercial
	home-entertainment software package. Creatures provides a simulated
	environment in which exist a number of synthetic agents that a user
	can interact with in real-time. The agents (known as ``creatures'')
	are intended as ``virtual pets''. The internal architecture of the
	creatures is inspired by animal biology. Each creature has a neural
	network responsible for sensory-motor coordination and behavior selection,
	and an ``artificial biochemistry'' that models a simple energy metabolism
	along with a ``hormonal'' system that interacts with the neural network
	to model diffuse modulation of neuronal activity and staged ontogenetic
	development. A Hebbian learning mechanism allows the neural network
	to adapt during the lifetime of a creature. Additionally, both the
	network architecture and details of the biochemistry for a creature
	are specified by a variable-length ``genetic'' encoding, allowing
	for evolutionary adaptation through sexual reproduction. Creatures,
	available on Windows95 and Macintosh platforms from late 1996, offers
	users an opportunity to engage with Artificial Life technologies.
	In addition to describing technical details, this paper concludes
	with a discussion of the scientific implications of the system. },
  citeseerurl = {http://portal.acm.org/citation.cfm?id=267658.267663},
  date-added = {2009-04-26 13:47:34 +0200},
  date-modified = {2009-04-26 13:53:39 +0200},
  isbn = {0-89791-877-0},
  url = {http://sigart.acm.org/proceedings/agents97/A157/A157.PDF}
}

@TECHREPORT{GrClMa96,
  author = {Grand, Stephen and Cliff, Dave and Malhotra, Anil},
  title = {Creatures: Artificial Life Autonomous Software Agents for Home Entertainment},
  institution = {Millennium Technical Report 9601; University of Sussex Technical
	Report CSRP434},
  year = {1996},
  type = {Presentation},
  number = {9601 / CSRP434},
  abstract = {This paper gives a technical description of Creatures, a commercial
	home-entertainment software package. Creatures provides a simulated
	environment in which exist a number of synthetic agents that a user
	can interact with in real-time. The agents (known as ``creatures'')
	are intended as ``virtual pets''. The internal architecture of the
	creatures is inspired by animal biology. Each creature has a neural
	network responsible for sensory-motor coordination and behavior selection,
	and an ``artificial biochemistry'' that models a simple energy metabolism
	along with a ``hormonal'' system that interacts with the neural network
	to model diffuse modulation of neuronal activity and staged ontogenetic
	development. A Hebbian learning mechanism allows the neural network
	to adapt during the lifetime of a creature. 
	
	Additionally, both the network architecture and details of the biochemistry
	for a creature are specified by a variable-length ``genetic'' encoding,
	allowing for evolutionary adaptation through sexual reproduction.
	Creatures, available on Windows95 and Macintosh platforms from late
	1996, offers users an opportunity to engage with Artificial Life
	technologies. In addition to describing technical details, this paper
	concludes with a discussion of the scientific implications of the
	system. },
  date-added = {2009-04-26 12:41:45 +0200},
  date-modified = {2009-04-26 13:46:21 +0200},
  doi = {10.1.1.19.6704},
  keywords = {Hebbain learning mechanism,sensory network,neural network,artificial
	life,virtual pets,norns,albia,creatures,agent,sensory-motor coordination}
}

@TECHREPORT{IsBuHe07,
  author = {Issacharoff, Limor and Buzna, Lubos and Helbing, Dirk},
  title = {Overview on Bio-inspired operation strategies (Deliverable D 2.2.3)},
  institution = {Integrated Risk Reduction of Information-based Infrastructure Systems
	(IRIIS)},
  year = {2007},
  type = {Integrated Project (IST Project 027568)},
  number = {027568},
  month = {September},
  date-added = {2009-04-26 12:32:51 +0200},
  date-modified = {2009-04-26 12:38:27 +0200},
  keywords = {Integrated Risk Reduction of Information-based Infrastructure Systems
	(IRIIS),Information Society Technologies (IST),evolutionnary based
	method,swarm intelligence,ant,routing algorithms,Artificial Immune
	System (AIS),genetic algorithms},
  url = {http://www.irriis.org/File.aspx?lang=2&oiid=9139&pid=572}
}

@INPROCEEDINGS{KhBeBe08,
  author = {Khelil, Hiba and Benyettou, Abdelkader and Bela{\"\i}d, Abdel},
  title = {Application du syst{\`e}me immunitaire artificiel pour la reconnaissance
	des chiffres},
  booktitle = {Maghrebian Conference on Software Engineering and Artificial Intelligence
	- MCSEAI'08 (2008)},
  year = {2008},
  month = {December},
  abstract = {La reconnaissance automatique de l'{\'e}criture occupe un espace important
	dans la recherche scientifique car elle offre une facilit{\'e} d'utilisation
	dans diff{\'e}rents domaines d'application : domaine bancaire, postal,
	le e-commerce{\ldots} De nombreuses m{\'e}thodes ont {\'e}t{\'e}
	utilis{\'e}es pour la reconnaissance d'{\'e}criture, dans cet article
	nous pr{\'e}senterons des m{\'e}thodes inspir{\'e}es du syst{\`e}me
	immunitaire naturel que nous appliquerons pour la reconnaissance
	des chiffres. Des r{\'e}sultats satisfaisants ont {\'e}t{\'e} not{\'e}s
	durant les exp{\'e}riences d'un taux maximal de 95% en vu d'am{\'e}lioration
	par hybridation avec des m{\'e}thodes d'optimisations.},
  date-added = {2009-04-26 13:41:22 +0200},
  date-modified = {2009-04-26 13:59:50 +0200},
  keywords = {Reconnaissance des chiffres, syst{\`e}me immunitaire naturel (NIS),
	syst{\`e}me immunitaire artificiel (AIS), antig{\`e}ne, cellules
	B m{\'e}moire,Artificial Immune System (AIS),B cell,Natural Immune
	System (NIS),antigen},
  url = {http://hal.archives-ouvertes.fr/docs/00/34/72/11/PDF/hiba-MCSEAI_08.pdf}
}

@ARTICLE{MIGSom01,
  author = {Mignonneau, Laurent and Sommerer, Christa},
  title = {Creating Artificial Life for Interactive Art and Entertainment},
  journal = {Leonardo},
  year = {2001},
  volume = {34},
  pages = {303--307},
  number = {4},
  month = {August},
  abstract = {Laurent Mignonneau and Christa Sommerer - Creating Artificial Life
	for Interactive Art and Entertainment - Leonardo 34:4 Leonardo 34.4
	(2001) 303-307 Artists' Article Creating Artificial Life for Interactive
	Art and Entertainment Laurent Mignonneau and Christa Sommerer [Figures]
	Abstract This article consists of two sections: the first provides
	a brief overview of artificial-life art and entertainment software,
	some of the main products and their peculiarities; and the second
	describes one of the authors' artificial-life software products,
	called Life Spacies II, which was created between 1997 and 1999.
	This system consists of a web page that allows users to create artificial-life
	creatures by simply typing in text characters using a web page "editor."
	Written text is used as genetic code to model the creature's body.
	The body shape subsequently influences the creature's ability to
	move, which in turn determines the creature's behavior, survival
	and reproduction within the Life Spacies II environment. In addition,
	users of the system can feed the creatures with text characters and
	thus even more actively influence the creatures' survival and reproduction
	in their environment. An Overview of Artificial-Life Art and Entertainment
	Software Artists and designers have created artificial-life art software
	since the early 1990s. Much of the inspiration for creating digital
	life-forms on a computer screen has been provided by Richard Dawkins's
	The Blind...},
  date-added = {2009-04-26 12:27:14 +0200},
  date-modified = {2009-04-26 12:31:35 +0200},
  keywords = {MUSE Projet,artificial life,life space,interactive art,Life Spacies
	II},
  url = {http://muse.jhu.edu/login?uri=/journals/leonardo/v034/34.4mignonneau.html}
}

@OTHER{RennardOrg,
  author = {Rennard, Jean-Philippe},
  date-added = {2009-04-26 16:31:43 +0200},
  date-modified = {2009-04-26 16:32:59 +0200},
  keywords = {artificial life,vie artificielle},
  title = {http://www.rennard.org/},
  url = {http://www.rennard.org/}
}

@OTHER{WikGenAlg,
  abstract = {Genetic algorithm
	
	From Wikipedia, the free encyclopedia A genetic algorithm (GA) is
	a search technique used in computing to find exact or approximate
	solutions to optimization and search problems. Genetic algorithms
	are categorized as global search heuristics. Genetic algorithms are
	a particular class of evolutionary algorithms (also known as evolutionary
	computation) that use techniques inspired by evolutionary biology
	such as inheritance, mutation, selection, and crossover (also called
	recombination).
	
	Contents
	
	1 Methodology 1.1 Initialization 1.2 Selection 1.3 Reproduction 1.4
	Termination 1.5 Simple generational genetic algorithm pseudocode
	1.6 Observations 2 Variants 3 Problem domains 4 History 5 Related
	techniques 6 Building block hypothesis 7 See also 8 Applications
	9 Notes 10 References 11 External links 11.1 Controversy 11.2 Applications
	11.3 Resources 11.4 Tutorials 11.5 Libraries
	
	Methodology
	
	Genetic algorithms are implemented as a computer simulation in which
	a population of abstract representations (called chromosomes or the
	genotype of the genome) of candidate solutions (called individuals,
	creatures, or phenotypes) to an optimization problem evolves toward
	better solutions. Traditionally, solutions are represented in binary
	as strings of 0s and 1s, but other encodings are also possible. The
	evolution usually starts from a population of randomly generated
	individuals and happens in generations. In each generation, the fitness
	of every individual in the population is evaluated, multiple individuals
	are stochastically selected from the current population (based on
	their fitness), and modified (recombined and possibly randomly mutated)
	to form a new population. The new population is then used in the
	next iteration of the algorithm. Commonly, the algorithm terminates
	when either a maximum number of generations has been produced, or
	a satisfactory fitness level has been reached for the population.
	If the algorithm has terminated due to a maximum number of generations,
	a satisfactory solution may or may not have been reached.
	
	Genetic algorithms find application in bioinformatics, phylogenetics,
	computational science, engineering, economics, chemistry, manufacturing,
	mathematics, physics and other fields.
	
	A typical genetic algorithm requirements:
	
	a genetic representation of the solution domain, a fitness function
	to evaluate the solution domain. A standard representation of the
	solution is as an array of bits. Arrays of other types and structures
	can be used in essentially the same way. The main property that makes
	these genetic representations convenient is that their parts are
	easily aligned due to their fixed size, that facilitates simple crossover
	operation. Variable length representations may also be used, but
	crossover implementation is more complex in this case. Tree-like
	representations are explored in Genetic programming and graph-form
	representations are explored in Evolutionary programming.
	
	The fitness function is defined over the genetic representation and
	measures the quality of the represented solution. The fitness function
	is always problem dependent. For instance, in the knapsack problem
	one wants to maximize the total value of objects that can be put
	in a knapsack of some fixed capacity. A representation of a solution
	might be an array of bits, where each bit represents a different
	object, and the value of the bit (0 or 1) represents whether or not
	the object is in the knapsack. Not every such representation is valid,
	as the size of objects may exceed the capacity of the knapsack. The
	fitness of the solution is the sum of values of all objects in the
	knapsack if the representation is valid, or 0 otherwise. In some
	problems, it is hard or even impossible to define the fitness expression;
	in these cases, interactive genetic algorithms are used.
	
	Once we have the genetic representation and the fitness function defined,
	GA proceeds to initialize a population of solutions randomly, then
	improve it through repetitive application of mutation, crossover,
	inversion and selection operators.
	
	
	Initialization
	
	Initially many individual solutions are randomly generated to form
	an initial population. The population size depends on the nature
	of the problem, but typically contains several hundreds or thousands
	of possible solutions. Traditionally, the population is generated
	randomly, covering the entire range of possible solutions (the search
	space). Occasionally, the solutions may be "seeded" in areas where
	optimal solutions are likely to be found.
	
	
	Selection
	
	During each successive generation, a proportion of the existing population
	is selected to breed a new generation. Individual solutions are selected
	through a fitness-based process, where fitter solutions (as measured
	by a fitness function) are typically more likely to be selected.
	Certain selection methods rate the fitness of each solution and preferentially
	select the best solutions. Other methods rate only a random sample
	of the population, as this process may be very time-consuming.
	
	Most functions are stochastic and designed so that a small proportion
	of less fit solutions are selected. This helps keep the diversity
	of the population large, preventing premature convergence on poor
	solutions. Popular and well-studied selection methods include roulette
	wheel selection and tournament selection.
	
	
	Reproduction
	
	The next step is to generate a second generation population of solutions
	from those selected through genetic operators: crossover (also called
	recombination), and/or mutation.
	
	For each new solution to be produced, a pair of "parent" solutions
	is selected for breeding from the pool selected previously. By producing
	a "child" solution using the above methods of crossover and mutation,
	a new solution is created which typically shares many of the characteristics
	of its "parents". New parents are selected for each child, and the
	process continues until a new population of solutions of appropriate
	size is generated. Although reproduction methods that are based on
	the use of two parents are more "biology inspired", recent researches
	(Islam Abou El Ata 2006) suggested more than two "parents" are better
	to be used to reproduce a good quality chromosome.
	
	These processes ultimately result in the next generation population
	of chromosomes that is different from the initial generation. Generally
	the average fitness will have increased by this procedure for the
	population, since only the best organisms from the first generation
	are selected for breeding, along with a small proportion of less
	fit solutions, for reasons already mentioned above.
	
	
	Termination
	
	This generational process is repeated until a termination condition
	has been reached. Common terminating conditions are:
	
	A solution is found that satisfies minimum criteria Fixed number of
	generations reached Allocated budget (computation time/money) reached
	The highest ranking solution's fitness is reaching or has reached
	a plateau such that successive iterations no longer produce better
	results Manual inspection Combinations of the above
	
	Simple generational genetic algorithm pseudocode
	
	Choose initial population Evaluate the fitness of each individual
	in the population Repeat until termination: (time limit or sufficient
	fitness achieved) Select best-ranking individuals to reproduce Breed
	new generation through crossover and/or mutation (genetic operations)
	and give birth to offspring Evaluate the individual fitnesses of
	the offspring Replace worst ranked part of population with offspring
	
	Observations
	
	There are several general observations about the generation of solutions
	via a genetic algorithm:
	
	Repeated fitness function evaluation for complex problems is often
	the most prohibitive and limiting segment of artificial evolutionary
	algorithms. Finding optimal solution to complex high dimensional,
	multimodal problems often requires very expensive fitness function
	evaluations. In real world problems such as structural optimization
	problems, one single function evaluation may require several hours
	to several days of complete simulation. Typical optimization method
	can not deal with such a type of problem. In this case, it may be
	necessary to forgo an exact evaluation and use an approximated fitness
	that is computationally efficient. It is apparent that amalgamation
	of approximate models may be one of the most promising approaches
	to convincingly use EA to solve complex real life problems. The "better"
	is only in comparison to other solution. As a result, the stop criterion
	is not clear. In many problems, GAs may have a tendency to converge
	towards local optima or even arbitrary points rather than the global
	optimum of the problem. This means that it does not "know how" to
	sacrifice short-term fitness to gain longer-term fitness. The likelihood
	of this occurring depends on the shape of the fitness landscape:
	certain problems may provide an easy ascent towards a global optimum,
	others may make it easier for the function to find the local optima.
	This problem may be alleviated by using a different fitness function,
	increasing the rate of mutation, or by using selection techniques
	that maintain a diverse population of solutions, although the No
	Free Lunch theorem proves that there is no general solution to this
	problem. A common technique to maintain diversity is to impose a
	"niche penalty", wherein, any group of individuals of sufficient
	similarity (niche radius) have a penalty added, which will reduce
	the representation of that group in subsequent generations, permitting
	other (less similar) individuals to be maintained in the population.
	This trick, however, may not be effective, depending on the landscape
	of the problem. Diversity is important in genetic algorithms (and
	genetic programming) because crossing over a homogeneous population
	does not yield new solutions. In evolution strategies and evolutionary
	programming, diversity is not essential because of a greater reliance
	on mutation. Operating on dynamic data sets is difficult, as genomes
	begin to converge early on towards solutions which may no longer
	be valid for later data. Several methods have been proposed to remedy
	this by increasing genetic diversity somehow and preventing early
	convergence, either by increasing the probability of mutation when
	the solution quality drops (called triggered hypermutation), or by
	occasionally introducing entirely new, randomly generated elements
	into the gene pool (called random immigrants). Again, evolution strategies
	and evolutionary programming can be implemented with a so-called
	"comma strategy" in which parents are not maintained and new parents
	are selected only from offspring. This can be more effective on dynamic
	problems. GAs cannot effectively solve problems in which the only
	fitness measure is a single right/wrong measure, as there is no way
	to converge on the solution (no hill to climb). In these cases, a
	random search may find a solution as quickly as a GA. However, if
	the situation allows the success/failure trial to be repeated giving
	(possibly) different results, then the ratio of successes to failures
	provides a suitable fitness measure. Selection is clearly an important
	genetic operator, but opinion is divided over the importance of crossover
	versus mutation. Some argue that crossover is the most important,
	while mutation is only necessary to ensure that potential solutions
	are not lost. Others argue that crossover in a largely uniform population
	only serves to propagate innovations originally found by mutation,
	and in a non-uniform population crossover is nearly always equivalent
	to a very large mutation (which is likely to be catastrophic). There
	are many references in Fogel (2006) that support the importance of
	mutation-based search, but across all problems the No Free Lunch
	theorem holds, so these opinions are without merit unless the discussion
	is restricted to a particular problem. Often, GAs can rapidly locate
	good solutions, even for difficult search spaces. The same is of
	course also true for evolution strategies and evolutionary programming.
	For specific optimization problems and problem instances, other optimization
	algorithms may find better solutions than genetic algorithms (given
	the same amount of computation time). Alternative and complementary
	algorithms include evolution strategies, evolutionary programming,
	simulated annealing, Gaussian adaptation, hill climbing, and swarm
	intelligence (e.g.: ant colony optimization, particle swarm optimization)
	and methods based on integer linear programming. The question of
	which, if any, problems are suited to genetic algorithms (in the
	sense that such algorithms are better than others) is open and controversial.
	As with all current machine learning problems it is worth tuning
	the parameters such as mutation probability, recombination probability
	and population size to find reasonable settings for the problem class
	being worked on. A very small mutation rate may lead to genetic drift
	(which is non-ergodic in nature). A recombination rate that is too
	high may lead to premature convergence of the genetic algorithm.
	A mutation rate that is too high may lead to loss of good solutions
	unless there is elitist selection. There are theoretical but not
	yet practical upper and lower bounds for these parameters that can
	help guide selection. The implementation and evaluation of the fitness
	function is an important factor in the speed and efficiency of the
	algorithm.
	
	Variants
	
	The simplest algorithm represents each chromosome as a bit string.
	Typically, numeric parameters can be represented by integers, though
	it is possible to use floating point representations. The floating
	point representation is natural to evolution strategies and evolutionary
	programming. The notion of real-valued genetic algorithms has been
	offered but is really a misnomer because it does not really represent
	the building block theory that was proposed by Holland in the 1970s.
	This theory is not without support though, based on theoretical and
	experimental results (see below). The basic algorithm performs crossover
	and mutation at the bit level. Other variants treat the chromosome
	as a list of numbers which are indexes into an instruction table,
	nodes in a linked list, hashes, objects, or any other imaginable
	data structure. Crossover and mutation are performed so as to respect
	data element boundaries. For most data types, specific variation
	operators can be designed. Different chromosomal data types seem
	to work better or worse for different specific problem domains.
	
	When bit strings representations of integers are used, Gray coding
	is often employed. In this way, small changes in the integer can
	be readily effected through mutations or crossovers. This has been
	found to help prevent premature convergence at so called Hamming
	walls, in which too many simultaneous mutations (or crossover events)
	must occur in order to change the chromosome to a better solution.
	
	Other approaches involve using arrays of real-valued numbers instead
	of bit strings to represent chromosomes. Theoretically, the smaller
	the alphabet, the better the performance, but paradoxically, good
	results have been obtained from using real-valued chromosomes.
	
	A very successful (slight) variant of the general process of constructing
	a new population is to allow some of the better organisms from the
	current generation to carry over to the next, unaltered. This strategy
	is known as elitist selection.
	
	Parallel implementations of genetic algorithms come in two flavours.
	Coarse grained parallel genetic algorithms assume a population on
	each of the computer nodes and migration of individuals among the
	nodes. Fine grained parallel genetic algorithms assume an individual
	on each processor node which acts with neighboring individuals for
	selection and reproduction. Other variants, like genetic algorithms
	for online optimization problems, introduce time-dependence or noise
	in the fitness function.
	
	It can be quite effective to combine GA with other optimization methods.
	GA tends to be quite good at finding generally good global solutions,
	but quite inefficient at finding the last few mutations to find the
	absolute optimum. Other techniques (such as simple hill climbing)
	are quite efficient at finding absolute optimum in a limited region.
	Alternating GA and hill climbing can improve the efficiency of GA
	while overcoming the lack of robustness of hill climbing.
	
	This means that the rules of genetic variation may have a different
	meaning in the natural case. For instance - provided that steps are
	stored in consecutive order - crossing over may sum a number of steps
	from maternal DNA adding a number of steps from paternal DNA and
	so on. This is like adding vectors that more probably may follow
	a ridge in the phenotypic landscape. Thus, the efficiency of the
	process may be increased by many orders of magnitude. Moreover, the
	inversion operator has the opportunity to place steps in consecutive
	order or any other suitable order in favour of survival or efficiency.
	(See for instance [1] or example in travelling salesman problem.)
	
	Population-based incremental learning is a variation where the population
	as a whole is evolved rather than its individual members.
	
	
	Problem domains
	
	Problems which appear to be particularly appropriate for solution
	by genetic algorithms include timetabling and scheduling problems,
	and many scheduling software packages are based on GAs. GAs have
	also been applied to engineering. Genetic algorithms are often applied
	as an approach to solve global optimization problems.
	
	As a general rule of thumb genetic algorithms might be useful in problem
	domains that have a complex fitness landscape as recombination is
	designed to move the population away from local optima that a traditional
	hill climbing algorithm might get stuck in.
	
	
	History
	
	Computer simulations of evolution started as early as in 1954 with
	the work of Nils Aall Barricelli, who was using the computer at the
	Institute for Advanced Study in Princeton, New Jersey.[1] [2] His
	1954 publication was not widely noticed. Starting in 1957 [3], the
	Australian quantitative geneticist Alex Fraser published a series
	of papers on simulation of artificial selection of organisms with
	multiple loci controlling a measurable trait. From these beginnings,
	computer simulation of evolution by biologists became more common
	in the early 1960s, and the methods were described in books by Fraser
	and Burnell (1970)[4] and Crosby (1973)[5]. Fraser's simulations
	included all of the essential elements of modern genetic algorithms.
	In addition, Hans Bremermann published a series of papers in the
	1960s that also adopted a population of solution to optimization
	problems, undergoing recombination, mutation, and selection. Bremermann's
	research also included the elements of modern genetic algorithms.
	Other noteworthy early pioneers include Richard Friedberg, George
	Friedman, and Michael Conrad. Many early papers are reprinted by
	Fogel (1998).[6]
	
	Although Barricelli, in work he reported in 1963, had simulated the
	evolution of ability to play a simple game,[7] artificial evolution
	became a widely recognized optimization method as a result of the
	work of Ingo Rechenberg and Hans-Paul Schwefel in the 1960s and early
	1970s - Rechenberg's group was able to solve complex engineering
	problems through evolution strategies [8] [9] [10] [11]. Another
	approach was the evolutionary programming technique of Lawrence J.
	Fogel, which was proposed for generating artificial intelligence.
	Evolutionary programming originally used finite state machines for
	predicting environments, and used variation and selection to optimize
	the predictive logics. Genetic algorithms in particular became popular
	through the work of John Holland in the early 1970s, and particularly
	his book Adaptation in Natural and Artificial Systems (1975). His
	work originated with studies of cellular automata, conducted by Holland
	and his students at the University of Michigan. Holland introduced
	a formalized framework for predicting the quality of the next generation,
	known as Holland's Schema Theorem. Research in GAs remained largely
	theoretical until the mid-1980s, when The First International Conference
	on Genetic Algorithms was held in Pittsburgh, Pennsylvania.
	
	As academic interest grew, the dramatic increase in desktop computational
	power allowed for practical application of the new technique. In
	the late 1980s, General Electric started selling the world's first
	genetic algorithm product, a mainframe-based toolkit designed for
	industrial processes. In 1989, Axcelis, Inc. released Evolver, the
	world's second GA product and the first for desktop computers. The
	New York Times technology writer John Markoff wrote[12] about Evolver
	in 1990.
	
	
	Related techniques
	
	Ant colony optimization (ACO) uses many ants (or agents) to traverse
	the solution space and find locally productive areas. While usually
	inferior to genetic algorithms and other forms of local search, it
	is able to produce results in problems where no global or up-to-date
	perspective can be obtained, and thus the other methods cannot be
	applied. Bacteriologic Algorithms (BA) inspired by evolutionary ecology
	and, more particularly, bacteriologic adaptation. Evolutionary ecology
	is the study of living organisms in the context of their environment,
	with the aim of discovering how they adapt. Its basic concept is
	that in a heterogeneous environment, you can't find one individual
	that fits the whole environment. So, you need to reason at the population
	level. BAs have shown better results than GAs on problems such as
	complex positioning problems (antennas for cell phones, urban planning,
	and so on) or data mining.[13] Cross-entropy method The Cross-entropy
	(CE) method generates candidates solutions via a parameterized probability
	distribution. The parameters are updated via cross-entropy minimization,
	so as to generate better samples in the next iteration. Cultural
	algorithm (CA) consists of the population component almost identical
	to that of the genetic algorithm and, in addition, a knowledge component
	called the belief space. Evolution strategies (ES, see Rechenberg,
	1994) evolve individuals by means of mutation and intermediate and
	discrete recombination. ES algorithms are designed particularly to
	solve problems in the real-value domain. They use self-adaptation
	to adjust control parameters of the search. Evolutionary programming
	(EP) involves populations of solutions with primarily mutation and
	selection and arbitrary representations. They use self-adaptation
	to adjust parameters, and can include other variation operations
	such as combining information from multiple parents. Extremal optimization
	(EO) Unlike GAs, which work with a population of candidate solutions,
	EO evolves a single solution and makes local modifications to the
	worst components. This requires that a suitable representation be
	selected which permits individual solution components to be assigned
	a quality measure ("fitness"). The governing principle behind this
	algorithm is that of emergent improvement through selectively removing
	low-quality components and replacing them with a randomly selected
	component. This is decidedly at odds with a GA that selects good
	solutions in an attempt to make better solutions. Gaussian adaptation
	(normal or natural adaptation, abbreviated NA to avoid confusion
	with GA) is intended for the maximisation of manufacturing yield
	of signal processing systems. It may also be used for ordinary parametric
	optimisation. It relies on a certain theorem valid for all regions
	of acceptability and all Gaussian distributions. The efficiency of
	NA relies on information theory and a certain theorem of efficiency.
	Its efficiency is defined as information divided by the work needed
	to get the information[14]. Because NA maximises mean fitness rather
	than the fitness of the individual, the landscape is smoothed such
	that valleys between peaks may disappear. Therefore it has a certain
	``ambition'' to avoid local peaks in the fitness landscape. NA is
	also good at climbing sharp crests by adaptation of the moment matrix,
	because NA may maximise the disorder (average information) of the
	Gaussian simultaneously keeping the mean fitness constant. Genetic
	programming (GP) is a related technique popularized by John Koza
	in which computer programs, rather than function parameters, are
	optimized. Genetic programming often uses tree-based internal data
	structures to represent the computer programs for adaptation instead
	of the list structures typical of genetic algorithms. Grouping Genetic
	Algorithm (GGA) is an evolution of the GA where the focus is shifted
	from individual items, like in classical GAs, to groups or subset
	of items.[15] The idea behind this GA evolution proposed by Emanuel
	Falkenauer is that solving some complex problems, a.k.a. clustering
	or partitioning problems where a set of items must be split into
	disjoint group of items in an optimal way, would better be achieved
	by making characteristics of the groups of items equivalent to genes.
	These kind of problems include Bin Packing, Line Balancing, Clustering
	w.r.t. a distance measure, Equal Piles, etc., on which classic GAs
	proved to perform poorly. Making genes equivalent to groups implies
	chromosomes that are in general of variable length, and special genetic
	operators that manipulate whole groups of items. For Bin Packing
	in particular, a GGA hybridized with the Dominance Criterion of Martello
	and Toth, is arguably the best technique to date. Harmony search
	(HS) is an algorithm mimicking musicians behaviors in improvisation
	process. Interactive evolutionary algorithms are evolutionary algorithms
	that use human evaluation. They are usually applied to domains where
	it is hard to design a computational fitness function, for example,
	evolving images, music, artistic designs and forms to fit users'
	aesthetic preference. Memetic algorithm (MA), also called hybrid
	genetic algorithm among others, is a relatively new evolutionary
	method where local search is applied during the evolutionary cycle.
	The idea of memetic algorithms comes from memes, which unlike genes,
	can adapt themselves. In some problem areas they are shown to be
	more efficient than traditional evolutionary algorithms. Simulated
	annealing (SA) is a related global optimization technique that traverses
	the search space by testing random mutations on an individual solution.
	A mutation that increases fitness is always accepted. A mutation
	that lowers fitness is accepted probabilistically based on the difference
	in fitness and a decreasing temperature parameter. In SA parlance,
	one speaks of seeking the lowest energy instead of the maximum fitness.
	SA can also be used within a standard GA algorithm by starting with
	a relatively high rate of mutation and decreasing it over time along
	a given schedule. Stochastic optimization is an umbrella set of methods
	that includes GAs and numerous other approaches. Tabu search (TS)
	is similar to Simulated Annealing in that both traverse the solution
	space by testing mutations of an individual solution. While simulated
	annealing generates only one mutated solution, tabu search generates
	many mutated solutions and moves to the solution with the lowest
	energy of those generated. In order to prevent cycling and encourage
	greater movement through the solution space, a tabu list is maintained
	of partial or complete solutions. It is forbidden to move to a solution
	that contains elements of the tabu list, which is updated as the
	solution traverses the solution space.
	
	Building block hypothesis
	
	Genetic algorithms are relatively simple to implement, but their behavior
	is difficult to understand. In particular it is difficult to understand
	why they are often successful in generating solutions of high fitness.
	The building block hypothesis (BBH) consists of:
	
	A description of an abstract adaptive mechanism that performs adaptation
	by recombining "building blocks", i.e. low order, low defining-length
	schemata with above average fitness. A hypothesis that a genetic
	algorithm performs adaptation by implicitly and efficiently implementing
	this abstract adaptive mechanism. (Goldberg 1989:41) describes the
	abstract adaptive mechanism as follows:
	
	Short, low order, and highly fit schemata are sampled, recombined
	[crossed over], and resampled to form strings of potentially higher
	fitness. In a way, by working with these particular schemata [the
	building blocks], we have reduced the complexity of our problem;
	instead of building high-performance strings by trying every conceivable
	combination, we construct better and better strings from the best
	partial solutions of past samplings. Just as a child creates magnificent
	fortresses through the arrangement of simple blocks of wood [building
	blocks], so does a genetic algorithm seek near optimal performance
	through the juxtaposition of short, low-order, high-performance schemata,
	or building blocks. (Goldberg 1989) claims that the building block
	hypothesis is supported by Holland's schema theorem.
	
	The building block hypothesis has been sharply criticized on the grounds
	that it lacks theoretical justification and experimental results
	have been published that draw its veracity into question. On the
	theoretical side, for example, Wright et al. state that
	
	"The various claims about GAs that are traditionally made under the
	name of the building block hypothesis have, to date, no basis in
	theory and, in some cases, are simply incoherent"[16] On the experimental
	side uniform crossover was seen to outperform one-point and two-point
	crossover on many of the fitness functions studied by Syswerda.[17]
	Summarizing these results, Fogel remarks that
	
	"Generally, uniform crossover yielded better performance than two-point
	crossover, which in turn yielded better performance than one-point
	crossover"[18] Syswerda's results contradict the building block hypothesis
	because uniform crossover is extremely disruptive of short schemata
	whereas one and two-point crossover are more likely to conserve short
	schemata and combine their defining bits in children produced during
	recombination.
	
	The debate over the building block hypothesis demonstrates that the
	issue of how GAs "work", (i.e. perform adaptation) is currently far
	from settled.
	
	
	See also
	
	Algorithmic efficiency Holland's schema theorem Genetic programming
	Fitness approximation
	
	Applications
	
	Artificial Creativity Automated design, including research on composite
	material design and multi-objective design of automotive components
	for crashworthiness, weight savings, and other characteristics. Automated
	design of mechatronic systems using bond graphs and genetic programming
	(NSF). Automated design of industrial equipment using catalogs of
	exemplar lever patterns. Automated design of sophisticated trading
	systems in the financial sector. Building phylogenetic trees.[19]
	Calculation of Bound states and Local-density approximations. Chemical
	kinetics (gas and solid phases) Configuration applications, particularly
	physics applications of optimal molecule configurations for particular
	systems like C60 (buckyballs). Container loading optimization. Code-breaking,
	using the GA to search large solution spaces of ciphers for the one
	correct decryption.[20] Design of water distribution systems. Distributed
	computer network topologies. Electronic circuit design, known as
	Evolvable hardware. File allocation for a distributed system. Parallelization
	of GAs/GPs including use of hierarchical decomposition of problem
	domains and design spaces nesting of irregular shapes using feature
	matching and GAs. Game Theory Equilibrium Resolution. Gene expression
	profiling analysis.[21] Learning Robot behavior using Genetic Algorithms.
	Learning fuzzy rule base using genetic algorithms. Linguistic analysis,
	including Grammar Induction and other aspects of Natural Language
	Processing (NLP) such as word sense disambiguation. Marketing Mix
	Analysis Mobile communications infrastructure optimization. Molecular
	Structure Optimization (Chemistry). Multiple criteria production
	scheduling.[22] Multiple population topologies and interchange methodologies.
	Mutation testing Operon prediction.[23] Optimisation of data compression
	systems, for example using wavelets. Pop music record producer[24].
	Protein folding and protein/ligand docking.[25] Plant floor layout.
	Representing rational agents in economic models such as the cobweb
	model. Bioinformatics: RNA structure prediction.[26] Bioinformatics:
	[Multiple Sequence Alignment].[27]. SAGA is available on: [2]. Bioinformatics
	Multiple sequence alignment.[28] Scheduling applications, including
	job-shop scheduling. The objective being to schedule jobs in a sequence
	dependent or non-sequence dependent setup environment in order to
	maximize the volume of production while minimizing penalties such
	as tardiness. Selection of optimal mathematical model to describe
	biological systems. Software engineering Solving the machine-component
	grouping problem required for cellular manufacturing systems. Tactical
	asset allocation and international equity strategies. Timetabling
	problems, such as designing a non-conflicting class timetable for
	a large university. Training artificial neural networks when pre-classified
	training examples are not readily obtainable (neuroevolution). Traveling
	Salesman Problem. Finding hardware bugs. [29] [30] Wireless Sensor/Ad-hoc
	Networks. [31] Data Center/Server Farm. [32]
	
	Notes
	
	^ Barricelli, Nils Aall (1954). "Esempi numerici di processi di evoluzione".
	Methodos: 45--68. ^ Barricelli, Nils Aall (1957). "Symbiogenetic
	evolution processes realized by artificial methods". Methodos: 143--182.
	^ Fraser, Alex (1957). "Simulation of genetic systems by automatic
	digital computers. I. Introduction". Aust. J. Biol. Sci. 10: 484--491.
	^ Fraser, Alex; Donald Burnell (1970). Computer Models in Genetics.
	New York: McGraw-Hill. ^ Crosby, Jack L. (1973). Computer Simulation
	in Genetics. London: John Wiley & Sons. ^ Fogel, David B. (editor)
	(1998). Evolutionary Computation: The Fossil Record. New York: IEEE
	Press. ^ Barricelli, Nils Aall (1963). "Numerical testing of evolution
	theories. Part II. Preliminary tests of performance, symbiogenesis
	and terrestrial life". Acta Biotheoretica (16): 99--126. ^ Rechenberg,
	Ingo (1973). Evolutionsstrategie. Stuttgart: Holzmann-Froboog. ^
	Schwefel, Hans-Paul (1974). Numerische Optimierung von Computer-Modellen
	(PhD thesis). ^ Schwefel, Hans-Paul (1977). Numerische Optimierung
	von Computor-Modellen mittels der Evolutionsstrategie : mit einer
	vergleichenden Einf{\"u}hrung in die Hill-Climbing- und Zufallsstrategie.
	Basel; Stuttgart: Birkh{\"a}user. ISBN 3764308761. ^ Schwefel, Hans-Paul
	(1981). Numerical optimization of computer models (Translation of
	1977 Numerische Optimierung von Computor-Modellen mittels der Evolutionsstrategie.
	Chichester ; New York: Wiley. ISBN 0471099880. ^ Markoff, John (1989).
	"What's the Best Answer? It's Survival of the Fittest". New York
	Times. ^ Baudry, Benoit; Franck Fleurey, Jean-Marc J{\'e}z{\'e}quel,
	and Yves Le Traon (March/April 2005). "Automatic Test Case Optimization:
	A Bacteriologic Algorithm" (PDF). IEEE Software (IEEE Computer Society)
	22: 76--82. doi:10.1109/MS.2005.30. ^ Kjellstr{\"o}m, G. (December
	1991). "On the Efficiency of Gaussian Adaptation". Journal of Optimization
	Theory and Applications 71 (3): 589--597. doi:10.1007/BF00941405.
	^ Falkenauer, Emanuel (1997). Genetic Algorithms and Grouping Problems.
	Chichester, England: John Wiley & Sons Ltd. ISBN 978-0-471-97150-4.
	^ Wright, A.H.; et al. (2003). "Implicit Parallelism". Proceedings
	of the Genetic and Evolutionary Computation Conference. ^ Syswerda,
	G. (1989). "Uniform crossover in genetic algorithms". J. D. Schaffer
	Proceedings of the Third International Conference on Genetic Algorithms,
	Morgan Kaufmann. ^ Fogel, David B. (2000). Evolutionary Computation:
	Towards a New Philosophy of Machine Intelligence. New York: IEEE
	Press. pp. 140. ^ Hill T, Lundgren A, Fredriksson R, Schi{\"o}th
	HB (2005). "Genetic algorithm for large-scale maximum parsimony phylogenetic
	analysis of proteins". Biochimica et Biophysica Acta 1725: 19--29.
	PMID 15990235. ^ Joachim De Zutter "Codebreaking" ^ To CC, Vohradsky
	J (2007). "A parallel genetic algorithm for single class pattern
	classification and its application for gene expression profiling
	in Streptomyces coelicolor". BMC Genomics 8: 49. doi:10.1186/1471-2164-8-49.
	PMID 17298664. ^ Bagchi Tapan P (1999). Multiobjective Scheduling
	by Genetic Algorithms. ^ Wang S, Wang Y, Du W, Sun F, Wang X, Zhou
	C, Liang Y (2007). "A multi-approaches-guided genetic algorithm with
	application to operon prediction". Artificial Intelligence in Medicine
	41: 151--159. doi:10.1016/j.artmed.2007.07.010. PMID 17869072. ^
	BBC News | Entertainment | To the beat of the byte ^ Willett P (1995).
	"Genetic algorithms in molecular recognition and design". Trends
	in Biotechnology 13: 516--521. doi:10.1016/S0167-7799(00)89015-0.
	PMID 8595137. ^ van Batenburg FH, Gultyaev AP, Pleij CW (1995). "An
	APL-programmed genetic algorithm for the prediction of RNA secondary
	structure". Journal of Theoretical Biology 174: 269--280. doi:10.1006/jtbi.1995.0098.
	PMID 7545258. ^ Notredame C, Higgins DG (1995). "SAGA a Genetic Algorithm
	for Multiple Sequence Alignment". Nulceic Acids Research 174: 1515.
	PMID 8628686. ^ Gondro C, Kinghorn BP (2007). "A simple genetic algorithm
	for multiple sequence alignment". Genetics and Molecular Research
	6: 964--982. PMID 18058716. ^ Hitoshi Iba, Sumitaka Akiba, Tetsuya
	Higuchi, Taisuke Sato: BUGS: A Bug-Based Search Strategy using Genetic
	Algorithms. PPSN 1992: ^ Ibrahim, W. and Amer, H.: An Adaptive Genetic
	Algorithm for VLSI Test Vector Selection ^ BiSNET/e - Distributed
	Software Systems Group, University of Massachusetts, Boston ^ SymbioticSphere
	- Distributed Software Systems Group, University of Massachusetts,
	Boston
	
	References
	
	Banzhaf, Wolfgang; Nordin, Peter; Keller, Robert; Francone, Frank
	(1998) Genetic Programming - An Introduction, Morgan Kaufmann, San
	Francisco, CA. Bies, Robert R; Muldoon, Matthew F; Pollock, Bruce
	G; Manuck, Steven; Smith, Gwenn and Sale, Mark E (2006). "A Genetic
	Algorithm-Based, Hybrid Machine Learning Approach to Model Selection".
	Journal of Pharmacokinetics and Pharmacodynamics (Netherlands: Springer):
	196--221. Fraser, Alex S. (1957). "Simulation of Genetic Systems
	by Automatic Digital Computers. I. Introduction". Australian Journal
	of Biological Sciences 10: 484--491. Goldberg, David E (1989), Genetic
	Algorithms in Search, Optimization and Machine Learning, Kluwer Academic
	Publishers, Boston, MA. Goldberg, David E (2002), The Design of Innovation:
	Lessons from and for Competent Genetic Algorithms, Addison-Wesley,
	Reading, MA. Fogel, David B (2006), Evolutionary Computation: Toward
	a New Philosophy of Machine Intelligence, IEEE Press, Piscataway,
	NJ. Third Edition Holland, John H (1975), Adaptation in Natural and
	Artificial Systems, University of Michigan Press, Ann Arbor Koza,
	John (1992), Genetic Programming: On the Programming of Computers
	by Means of Natural Selection, MIT Press. ISBN 0-262-11170-5 Michalewicz,
	Zbigniew (1999), Genetic Algorithms + Data Structures = Evolution
	Programs, Springer-Verlag. Mitchell, Melanie, (1996), An Introduction
	to Genetic Algorithms, MIT Press, Cambridge, MA. Poli, R., Langdon,
	W. B., McPhee, N. F. (2008). A Field Guide to Genetic Programming.
	Lulu.com, freely available from the internet. ISBN 978-1-4092-0073-4.
	Rechenberg, Ingo (1994): Evolutionsstrategie '94, Stuttgart: Fromman-Holzboog.
	Schmitt, Lothar M; Nehaniv, Chrystopher L; Fujii, Robert H (1998),
	Linear analysis of genetic algorithms, Theoretical Computer Science
	208: 111-148 Schmitt, Lothar M (2001), Theory of Genetic Algorithms,
	Theoretical Computer Science 259: 1-61 Schmitt, Lothar M (2004),
	Theory of Genetic Algorithms II: models for genetic operators over
	the string-tensor representation of populations and convergence to
	global optima for arbitrary fitness function under scaling, Theoretical
	Computer Science 310: 181-231 Schwefel, Hans-Paul (1974): Numerische
	Optimierung von Computer-Modellen (PhD thesis). Reprinted by Birkh{\"a}user
	(1977). Vose, Michael D (1999), The Simple Genetic Algorithm: Foundations
	and Theory, MIT Press, Cambridge, MA. Whitley, D. (1994). A genetic
	algorithm tutorial. Statistics and Computing 4, 65--85.
	
	External links
	
	[3] Search of Global Minimum by genetic algorithme
	
	Controversy
	
	The Fundamental Problem with the Building Block Hypothesis A description
	and critique of the assumptions that undergird the building block
	hypothesis
	
	Applications
	
	Genetic Arm Simulation of a mechanical arm trained using genetic algorithms.
	Custom goals can be defined using a scripting language. A sample
	video is available on page. Antenna optimization for NASA A successful
	application of genetic algorithms. Genesis-SGA Seo genetic Algorithm
	Genetic algorithms applied to the theme SEO (Search Engine Optimization)
	
	Resources
	
	DigitalBiology.NET Vertical search engine for GA/GP resources Genetic
	Algorithms Index The site Genetic Programming Notebook provides a
	structured resource pointer to web pages in Genetic Algorithms field
	
	Tutorials
	
	A Field Guide to Genetic Programming A book, freely downloadable under
	a Creative Commons license. Introduction to Genetic Algorithms with
	interactive Java applets For experimenting with GAs online A Practical
	Tutorial on Genetic Algorithm Programming a Genetic Algorithm step
	by step. A Genetic Algorithm Tutorial by Darrell Whitley Computer
	Science Department Colorado State University An excellent tutorial
	with lots of theory Cross discipline example applications for GAs
	with references. Global Optimization Algorithms - Theory and Application
	
	Libraries
	
	Jenes An optimized Java library for Genetic Algorithms. Pyevolve A
	python framework for Genetic Algorithms. ParadisEO A powerful C++
	framework dedicated to the reusable design of metaheuristics, included
	genetic algorithms. Genetic Algorithms in Ruby GAlib A C++ Library
	of Genetic Algorithm Components GAEDALib A C++ Library of Evolutive
	Algotithms (GAs, EDAs, DEs and others) based in GAlib, and supporting
	to MOS and parallel computing Jenetics Genetic Algorithm Library
	written in Java. A Fortran code (PIKAIA) with a tutorial by Paul
	Charbonneau and Barry Knapp, National Center for Atmospheric Research.
	An excellent tutorial and a versatile public domain code. PIKAIA
	is also available in a version for Microsoft Excel, as well as a
	parallel processing version. ga Genetic Algorithm in MATLAB (How
	GA in MATLAB works) gamultiobj Multitobjective Genetic Algorithm
	in MATLAB GARAGe Michigan State University's Genetic Algorithm library
	in C, GALLOPS speedyGA A fast lightweight genetic algorithm in Matlab.
	GAOT The Genetic Algorithm Optimization Toolbox (GAOT) for Matlab,
	by NCSU JGAP Java Genetic Algorithms Package features comprehensive
	unit tests Retrieved from "http://en.wikipedia.org/wiki/Genetic_algorithm"
	Categories: Cybernetics | Intelligence | Genetic algorithms | Search
	algorithms Hidden categories: All articles with unsourced statements
	| Articles with unsourced statements since January 2009 | Articles
	with unsourced statements since August 2007 | Articles with unsourced
	statements since November 2008 This page was last modified on 24
	April 2009, at 14:54 (UTC). All text is available under the terms
	of the GNU Free Documentation License. (See Copyrights for details.)
	Wikipedia{\textregistered} is a registered trademark of the Wikimedia
	Foundation, Inc., a U.S. registered 501(c)(3) tax-deductible nonprofit
	charity.},
  author = {Wikipedia},
  date-added = {2009-04-26 16:30:26 +0200},
  date-modified = {2009-04-26 16:58:29 +0200},
  keywords = {genetic algorithms,wikipedia},
  title = {http://en.wikipedia.org/wiki/{G}enetic\_algorithm},
  url = {http://en.wikipedia.org/wiki/Genetic_algorithm}
}

@OTHER{WikiAurBlu,
  abstract = {Aurelia and Blue Moon
	
	From Wikipedia, the free encyclopedia Aurelia and Blue Moon are hypothetical
	examples of a planet and a moon on which extraterrestrial life could
	evolve. They are the outcome of a collaboration between television
	company Blue Wave Productions Ltd. and a group of American and British
	scientists who were collectively commissioned by National Geographic.
	The team used a combination of accretion theory, climatology, and
	xenobiology to imagine the most likely locations for extraterrestrial
	life and most probable evolutionary path such life would take.
	
	The beginning concepts appeared in a two-part television broadcast
	called Alien Worlds, aired in 2005 in the UK by Channel 4. Channel
	4 has also released a DVD of the programme. The show was also aired
	on the National Geographic Channel as Extraterrestrial.
	
	The first program in the series focused on Aurelia, a hypothetical
	Earth-sized extrasolar planet orbiting a red dwarf star in our local
	area of the milky way. This hypothetical world might resemble the
	recently discovered real exoplanet Gliese 581 d. The second focuses
	on a moon called Blue Moon, which orbits an enormous gas giant that
	is itself orbiting a binary star system. In turn, Blue Moon and its
	parent gas giant may resemble HD 28185 b and 55 Cancri f, two other
	real exoplanets. The show blurred the lines between science fiction
	and science fact.
	
	Contents
	
	1 Reasons for theorizing 2 Aurelia 2.1 Tidal lock 2.2 Traditional
	theories 2.3 Traditional assumptions tested 2.4 Continued theories
	3 Blue Moon 4 See also 5 References 6 External links
	
	Reasons for theorizing
	
	
	Life (as we know it) is believed to only be able to form in the "habitable
	zone" around a parent star. Note how close the planet has to be in
	the case of a red dwarf. Discoveries regarding extra solar planets
	were first published in 1989 raising the prospect of whether life
	(as we know it or imagine it) could be supported on other planets.
	It is currently believed that for this to happen a planet must orbit
	in a relatively narrow band around its parent star, where temperatures
	are suitable for water to exist as a liquid. This region is called
	the habitable zone.
	
	The smallest non-pulsar planet yet found (as of April 2009), Gliese
	581 e, has a mass larger than Earth's and orbits the red dwarf star
	Gliese 581. All currently known smaller extra solar bodies orbit
	pulsar PSR 1257+12.
	
	The sensitivity of current detection methods makes it difficult for
	scientists to search for terrestrial planets smaller than this. To
	allow smaller bodies to be detected, NASA is studying a project called
	the Terrestrial Planet Finder (TPF), a two-telescope concept slated
	to begin launching around 2014. However, Congressional spending limits
	under House Resolution 20 passed on January 31, 2007 by the U.S.
	House of Representatives and February 14 by the U.S. Senate have
	all but canceled the program.
	
	Prior to the TPF's cancellation, astrophysicists had begun speculating
	about the best places to point the telescope in order to find Earth-like
	planets. While life on earth has formed around a stable yellow dwarf,
	solar twins are not as common in the galaxy as red dwarf stars (which
	have a mass of less than one-half that of the Sun and consequently
	emit less heat), or bigger, brighter Blue giants. In addition, it
	is estimated that more than a quarter of all stars are at least binary
	systems, with as many as 10% of these systems containing more than
	two stars (trinary etc.)---unlike our own sun, which has no companion.
	Therefore it may be prudent to consider how life might evolve in
	such environments. Such speculation may still be of use should a
	future planet-finding telescope be launched.
	
	
	Aurelia
	
	The scientists on the project theorized that aiming the TPF at a red
	dwarf star might yield the best opportunities for seeing smaller
	planets. Due to the slow rate at which they burn hydrogen, red dwarfs
	have an enormous estimated lifespan; allowing plenty of time for
	life to evolve on surrounding planets.
	
	
	Tidal lock
	
	However, the dwarf's smaller nature and feeble heat/light output would
	mean that such a planet would need to be particularly close to the
	star's surface. The cost of such an orbit would be that an Earth-sized
	body would become tidally locked. When this happens, the object presents
	the same face to its parent at all times as it orbits, just as the
	Moon does with the Earth (more technically, one sidereal day is exactly
	equal to one year for the orbiting body).
	
	
	Traditional theories
	
	Traditional scientific theories proposed that such a tidally locked
	planet might be incapable of holding on to an atmosphere. Having
	such a slow rotation would weaken the magnetic effect that protects
	the atmosphere from being blown away by solar wind (see Rare Earth
	hypothesis).
	
	
	Traditional assumptions tested
	
	Nonetheless, the scientists employed by the programme decided to test
	the traditional assumptions for such a planet and start a model out
	for it from a proplyd through to its eventual death. Their estimations
	suggested such a planet could indeed hold on to its atmosphere, although
	with freakishly unusual results by Earth standards. Half of Aurelia
	would be in perpetual darkness and would be in a permanent ice age.
	The other half would contain a giant, unending hurricane with permanent
	torrential rain at the point directly opposite the local star. In
	between these two zones would be a place suitable for life.
	
	
	Continued theories
	
	The theorizations continued, and assuming that there was land in this
	habitable zone, it would be likely to form large networks of river
	deltas and swampland, due to rain runoff from the nearby storm.
	
	At the far end of assumptions about Aurelia were attempts to construct
	lifeforms based on Earthly evolutionary models and how ecosystems
	might develop. The scientists assumptions included the idea that
	the long life of a red dwarf allows for evolution to fine tune any
	ecosystem on the planet. The scientists involved in the project hypothesized
	that the vast majority, if not all, of extra-solar biology will be
	carbon based.
	
	This assumption is often referred to by critics as carbon chauvinism,
	as it may be possible for life to form that is not based on carbon.
	However, carbon is more flexible than other elements, allowing life
	it is made of to evolve at a much faster rate. Since all environments
	are likely to undergo massive change, this is vital.
	
	From this carbon-based hypothesis the scientific team assumed some
	form of staple photosynthesizing animal/plant combination would be
	the principle autotroph. They decided upon a plant-like creature
	called a Stinger Fan. It has five hearts and limited mobility. Its
	fan-like leaves trap the red dwarf star's energy to produce sugars.
	Its hearts pump them around its body.[1]
	
	Feeding upon the Stinger Fans are six-legged semi-amphibious creatures
	called Mudpods, somewhat like a cross between a beaver and a large
	newt with the eyes of a snail. Upon that animal, a large emu-like
	carnivore, a Gulphog, is the main predator. Finally, with no apparent
	explanation from within the Alien Worlds program, there is a second
	semi-amphibious creature called the Hysteria which was a cross between
	a plague of tadpoles and piranha. These tiny creatures can form one
	huge super organism and move together up banks to paralyze and consume
	other animals.
	
	The planet's ecosystem suffers from a number of particular peculiarities,
	most notably evolutionary quirks to allow all living organisms to
	detect and avoid solar flares. Red dwarf stars are unstable and eject
	frequent solar flares. Such intense ultraviolet radiation is deadly
	to all carbon-based life forms as it breaks down the atomic bonds
	formed by organic compounds. However, the flare stage might only
	be when they are relatively young. See, Habitability of red dwarf
	systems
	
	
	Blue Moon
	
	
	A hypothetical rendition of The Blue Moon orbiting high above the
	plane of its parent gas giant planet. Blue Moon is covered in life-giving
	water and an atmosphere so dense that enormous creatures can take
	flight. The Blue Moon orbits a Water Cloud Jovian planet (a Jupiter-like
	planet that is cool enough to have visible rain clouds in its atmosphere)
	orbiting a close binary star system. The Blue Moon itself is roughly
	an earth mass but has an air pressure around three times that of
	Earth's at sea level.
	
	A distinguishing feature of Blue Moon is that it has no polar ice
	caps: the thick atmosphere keeps temperatures constant across the
	moon's surface. There is also a greenish haze over the moon from
	large carpets of floating moss and algae.
	
	The denser atmosphere allows more massive creatures to remain airborne
	than on Earth. Skywhales, gargantuan whale-like animals which evolved
	away from the ocean into the air, fill the ecological niche this
	creates. Because of the increased muscle power from excess atmospheric
	oxygen, these creatures can have wingspans of ten metres and remain
	airborne their entire lives. They feed on the previously mentioned
	air moss.
	
	Humans could not live on the Blue Moon: the high levels of oxygen
	push the atmosphere to the brink of spontaneous combustion during
	lightning storms. Carbon dioxide levels are thirty times higher than
	on Earth making the air clammy and warm. Like our moon, Blue Moon
	is "tidally locked", meaning it keeps the same side of the moon faced
	towards its planet.
	
	With an orbital time of roughly ten days, that means five days of
	continuous night and five days of continuous daytime. The long days
	and nights also create strong cross-hemisphere winds that help keep
	the Skywhales afloat, in addition to the density of the atmosphere.
	
	The Skywhales are prey to the insectoid Caped Stalkers, colony-living
	predators that have several different tasks. Scouts find Skywhales
	and mark them with a special scent, then return to the nest to spread
	the word. Workers then swarm out in huge numbers, detecting the whale
	and working together to bring them down from the sky and kill them.
	Finally, there is a Queen, who stays in the nest and constantly lays
	eggs that become new Stalkers. The Stalkers are also prey, for the
	Pagoda branches are draped with the lethal webs of the plant-like
	Ghost traps. Once a Stalker is helplessly caught in a Ghost trap
	web, the carnivore uses its tentacles to lift its catch up into its
	mouth, to be digested in a primitive stomach of acid.
	
	As well as Skywhales, giant Kites also fly above the forest canopy.
	These parasole-like grazers can grow up to five metres in diameter
	and still stay airborne. Their tethers help control their floating,
	whiles their jellyfish-like tentacles snatch Helibug larv{\ae} from
	the water-filled skyponds. Helibugs have a trilaterally symmetrical
	body plan, with three eyes, three wings, three legs, three mouth
	parts and three tongues.
	
	The entire Blue Moon land mass is coated in two main plant types,
	the Pagoda Trees and the Balloon Plants. Pagoda Trees interconnect
	with each other to allow them to grow 700 feet high. Their hollow
	leaves collect rainwater, since the trees are too tall to draw it
	from the ground. Balloon Plants release their seeds by filling them
	with hydrogen to float in the dense atmosphere, in a similar way
	to kelp on Earth.
	
	
	See also
	
	Concepts and theories Origin of life Panspermia Planetary habitability
	Snaiad Terraforming Xenolinguistics Research efforts Darwin IV NASA
	Astrobiology Institute SETI Alien Planet, a similar program on the
	Discovery Channel
	
	References
	
	^ "Alien Worlds: Stinger Fan". Retrieved on 2007-04-29.
	
	External links
	
	National Geographic: "Extraterrestrial" Retrieved from "http://en.wikipedia.org/wiki/Aurelia_and_Blue_Moon"
	Categories: Fictional planets Hidden categories: All articles with
	unsourced statements | Articles with unsourced statements since January
	2009 This page was last modified on 23 April 2009, at 23:15 (UTC).
	All text is available under the terms of the GNU Free Documentation
	License. (See Copyrights for details.) Wikipedia{\textregistered}
	is a registered trademark of the Wikimedia Foundation, Inc., a U.S.
	registered 501(c)(3) tax-deductible nonprofit charity.},
  author = {Wikipedia},
  date-added = {2009-04-26 16:34:35 +0200},
  date-modified = {2009-04-26 16:58:04 +0200},
  keywords = {aurelia,blue moon,wikipedia,},
  title = {http://en.wikipedia.org/wiki/{A}urelia\_and\_{B}lue\_{M}oon},
  url = {http://en.wikipedia.org/wiki/Aurelia_and_Blue_Moon}
}

@OTHER{WikiCelAut,
  abstract = {Cellular automaton
	
	From Wikipedia, the free encyclopedia Gosper's Glider Gun creating
	"gliders" in the cellular automaton Conway's Game of Life. This is
	by no means the most complex pattern devised: Conway and his students
	devised a pattern with 1013 cells, that acts as a Turing complete
	computer.[1] A cellular automaton (plural: cellular automata) is
	a discrete model studied in computability theory, mathematics, theoretical
	biology and microstructure modeling. It consists of a regular grid
	of cells, each in one of a finite number of states, "On" and "Off"
	for example. The grid can be in any finite number of dimensions.
	For each cell, a set of cells called its neighborhood (usually including
	the cell itself) is defined relative to the specified cell. For example,
	the neighborhood of a cell might be defined as the set of cells a
	distance of 2 or less from the cell. An initial state (time t=0)
	is selected by assigning a state for each cell. A new generation
	is created (advancing t by 1), by making the new state of each cell
	a value according to a rule that depends on the current state of
	the cell and the states of the cells in its neighborhood. For example,
	the rule might be that the cell is "On" in the next generation if
	exactly two of the cells in the neighborhood are "On" in the current
	generation, otherwise the cell is "Off" in the next generation. The
	rule for updating must be the same for each cell and does not change
	over time. Each generation the rules are applied to the whole grid
	simultaneously.},
  author = {Wikipedia},
  date-added = {2009-04-26 16:33:04 +0200},
  date-modified = {2009-04-26 16:58:36 +0200},
  keywords = {cellular automata,wikipedia},
  title = {http://en.wikipedia.org/wiki/{C}ellular\_automata},
  url = {http://en.wikipedia.org/wiki/Cellular_automata}
}

